[[jus]]
= Distributed Implementation of java.util.stream API

You can use Java's standard
https://docs.oracle.com/javase/8/docs/api/java/util/stream/package-summary.html[`java.util.stream`]
API with any Jet data source. Java specifies that a stream computation
starts upon invoking the terminal operation on it (such as `forEach()`).
At that point Jet converts the expression into a Core API DAG and
submits it for execution.

Here's a simple example that takes an `IMap` of cities and their
latitudes and returns only the southern cities:

[source]
----
include::{javasource}/JUS.java[tag=s1]
----

Here's how to supply an arbitrary batch data source. In this example
Jet will read lines of text from all the files in the given directory
and parse them into words:

[source]
----
include::{javasource}/JUS.java[tag=s2]
----

== Distributed Collectors

The terminal operation of a java.util.stream expression uses a
_collector_ such as `Collectors.toList()`. Java's collectors don't
work in a Jet job because they aren't serializable. Jet therefore
provides you with its own serializable collectors. You can find them in
the
{jet-javadoc}/stream/DistributedCollectors.html[`DistributedCollectors`]
utility class. Keep in mind that the collectors such as `toMap()`,
`toCollection()`, `toList()`, and `toArray()` create a local data
structure and load all the results into it. This works fine with the
regular JDK streams, where everything is local, but may easily fail in
the context of a distributed computing job.

For example, the following innocent-looking code will fail with an
`OutOfMemoryError` because it requests to load the whole contents of a
distributed map into a single place:

[source]
----
include::{javasource}/JUS.java[tag=s3]
----

<1> `large_map` is a distributed map with 5GB per member in a 10-member
cluster
<2> attempts to build a `HashMap` of 50GB

This is why Jet distinguishes between the standard `java.util.stream`
collectors and the Jet-specific `Reducer` s. A `Reducer` puts the data
into a distributed data structure and knows how to leverage its native
partitioning scheme to optimize the access pattern across the cluster.

These are some of the `Reducer` implementations provided in Jet:

* {jet-javadoc}/stream/DistributedCollectors.html#toIMap-java.lang.String-[`toIMap()`]:
writes the data to a Hazelcast `IMap`.
* {jet-javadoc}/stream/DistributedCollectors.html#groupingByToIMap-java.lang.String-com.hazelcast.jet.function.DistributedFunction-[`groupingByToIMap()`]:
performs a grouping operation and then writes the results to a Hazelcast
`IMap`.
* {jet-javadoc}/stream/DistributedCollectors.html#toIList-java.lang.String-[`toIList()`]:
Writes the data to a Hazelcast `IList`.

`Reducer` behaves analogously to Pipeline API's sinks: if the reqeusted
Hazelcast data structure doesn't exist, it creates it, but it doesn't
clear it if it already exists.

A distributed data structure is cluster-managed, therefore you can't
just create one and forget about it; it will live on until you
explicitly destroy it. This has consequences on the fit between Jet and
the `java.util.stream` API. For example, `java.util.stream` performs
group-and-aggregate with `Collectors.groupingBy`, which is a composite
collector: it maintains a `HashMap` of collections and delegates to the
"downstream" collector you provide to manage the collections that hold
all the items with the same key. Since the outer `HashMap` is hardcoded,
you cannot use this collector to store the results in an `IMapJet`. This
is why Jet provides `groupingByToIMap()`.

== Word Count

You can perform the <<get-started, Word Count>> operation on a Hazelcast
`IList` filled with lines of text like this:

[source]
----
include::{javasource}/JUS.java[tag=s4]
----

After you run this, there will be a durable Hazelcast IMap with the
name "result" in the Jet cluster, whether or not you keep the
reference you got as the returned value.
