[[jus]]
= Distributed Implementation of java.util.stream API

You can use Java's standard
https://docs.oracle.com/javase/8/docs/api/java/util/stream/package-summary.html[`java.util.stream`]
API with any Jet data source. Java specifies that a stream computation
starts upon invoking the terminal operation on it (such as `forEach()`).
At that point Jet converts the expression into a Core API DAG and
submits it for execution.

Here's a simple example that takes an `IMap` of cities and their
latitudes and returns only the southern cities:

[source]
----
include::{javasource}/JUS.java[tag=s1]
----

Here's how to supply an arbitrary batch data source. In this example
Jet will read lines of text from all the files in the given directory
and parse them into words:

[source]
----
include::{javasource}/JUS.java[tag=s2]
----

== Distributed Collectors

The terminal operation of a java.util.stream expression uses a
_collector_ such as `Collectors.toList()`. Java's collectors don't
work in a Jet job because they aren't serializable. Jet therefore
provides you with its own serializable collectors. You can find them in
the
{jet-javadoc}/stream/DistributedCollectors.html[`DistributedCollectors`]
utility class. Keep in mind that the collectors such as `toMap()`,
`toCollection()`, `toList()`, and `toArray()` create a local data
structure and load all the results into it. This works fine with the
regular JDK streams, where everything is local, but may easily fail in
the context of a distributed computing job.

For example, the following innocent-looking code will fail with an
`OutOfMemoryError` because it requests to load the whole contents of a
distributed map into a single place:

[source]
----
include::{javasource}/JUS.java[tag=s3]
----

<1> `large_map` is a distributed map with 5GB per member in a 10-member cluster
<2> attempts to build a HashMap of 50GB

This is why Jet distinguishes between the standard `java.util.stream`
collectors and the Jet-specific `Reducer` s. A `Reducer` puts the data
into a distributed data structure and knows how to leverage its native
partitioning scheme to optimize the access pattern across the cluster.

These are some of the `Reducer` implementations provided in Jet:

* `toIMap()`: writes the data to a new Hazelcast `IMap`.
* `groupingByToIMap()`: performs a grouping operation and then writes
the results to a Hazelcast `IMap`. This uses a more efficient
implementation than the standard `groupingBy()` collector and can make
use of partitioning.
* `toIList()`: Writes the data to a new Hazelcast `IList`.

A distributed data structure is cluster-managed, therefore you can't
just create one and forget about it; it will live on until you
explicitly destroy it. That means it's inappropriate to use as a part of
a data item inside a larger collection, a further consequence being that
a `Reducer` is inappropriate as a downstream collector; that's where
the JDK-standard collectors make sense.

== Word Count

The word count example that was described in the
<<get-started, Get Started>> section can be rewritten using the `java.util.stream` API as follows:

[source]
----
IMap<String, Long> counts = lines
                .stream()
                .flatMap(word -> Stream.of(word.split("\\W+")))
                .collect(DistributedCollectors.toIMap(w -> w, w -> 1L, (left, right) -> left + right));
----

