= Watch out for Capturing Lambdas

A typical Jet pipeline involves lambda expressions. Since the whole
pipeline definition must be serialized to be sent to the cluster, the
lambda expressions must be serializable as well. The Java standard
provides an essential building block: if the static type of the lambda
is a subtype of `Serializable`, you will automatically get a lambda
instance that can serialize itself.

None of the functional interfaces in the JDK extend `Serializable`, so
we had to mirror the entire `java.util.function` package in our own
`com.hazelcast.jet.function` with all the interfaces subtyped and made
`Serializable`. Each subtype has the name of the original with
`Distributed` prepended. For example, a `DistributedFunction` is just
like `Function`, but implements `Serializable`. We use these types
everywhere in the Pipeline API.

As always with this kind of magic, auto-serializability of lambdas has its
flipside: it is easy to overlook what's going on.

If the lambda references a variable in the outer scope, the variable is
captured and must also be serializable. If it references an instance
variable of the enclosing class, it implicitly captures `this` so the
entire class will be serialized. For example, this will fail because
`JetJob1` doesn't implement `Serializable`:

[source]
----
include::{javasource}/Considerations.java[tag=s3]
----

<1> Refers to `instanceVar`, capturing `this`, but `JetJob1` is not
`Serializable` so this call will fail.

Just adding `implements Serializable` to `JetJob1` would be a viable
workaround here. However, consider something just a bit different:

[source]
----
include::{javasource}/Considerations.java[tag=s4]
----

<1> A non-serializable field.

<2> Refers to `instanceVar`, capturing `this`. `JetJob2` is declared as
`Serializable`, but has a non-serializable field and this fails.

Even though we never refer to `fileOut`, we are still capturing the
entire `JetJob2` instance. We might mark `fileOut` as `transient`, but
the sane approach is to avoid referring to instance variables of the
surrounding class. We can simply achieve this by assigning to a local
variable, then referring to that variable inside the lambda:

[source]
----
include::{javasource}/Considerations.java[tag=s5]
----

<1> Declare a local variable that loads the value of the instance field.

<2> By referring to the local variable `findMe` we avoid capturing
`this` and the job runs fine.

Another common pitfall is capturing an instance of `DateTimeFormatter`
or a similar non-serializable class:

[source]
----
include::{javasource}/Considerations.java[tag=s6]
----

<1> Captures the non-serializable `formatter`, so this fails.

Sometimes we can get away by using one of the preconfigured formatters
available in the JDK:

[source]
----
include::{javasource}/Considerations.java[tag=s7]
----

<1> Accesses the static final field `ISO_LOCAL_TIME`. Static fields are
not subject to lambda capture, they are dereferenced when the code runs
on the target machine.

This refers to a `static final` field in the JDK, so the instance is
available on any JVM. If this is not available, you may create a
static final field in your own class, but you can also use
`mapUsingContext()`. In this case you provide a serializable factory
that Jet will ask to create an object on the target member. The object
it returns doesn't have to be serializable. Here's an example of that:

[source]
----
include::{javasource}/Considerations.java[tag=s8]
----

<1> Create a `ContextFactory`.
<2> Supply it to `mapUsingContext()`.
<3> Your mapping function now gets the object the factory created.

= Performance Considerations

== Standard Java Serialization is Slow

When it comes to serializing the description of a Jet job, performance
is not critical. However, for the data passing through the pipeline,
the cost of the serialize-deserialize cycle can easily dwarf the cost of
actual data transfer, especially on high-end LANs typical for data
centers. In this context the performance of Java serialization is so
poor that it regularly becomes the bottleneck. This is due to its heavy
usage of reflection, overheads in the serialized form, etc.

Since Hazelcast IMDG faced the same problem a long time ago, we have
mature support for optimized custom serialization and in Jet you can
use it for stream data. In essence, you must implement a
`StreamSerializer` for the objects you emit from your processors and
register it in Jet configuration:

[source]
----
include::{javasource}/Considerations.java[tag=s9]
----

Consult the chapter on
{hz-refman}#custom-serialization[custom serialization]
in Hazelcast IMDG's reference manual for more details.

Note the limitation implied here: the serializers must be registered
with Jet on startup because this is how it is supported in Hazelcast
IMDG. There is a plan to improve this and allow serializers to be
registered on individual Jet jobs.

== Capacity of the Concurrent Queues

By default, Jet runs each internal DAG vertex, roughly equivalent to
each step of the computation (such as `map` or `aggregate`), at maximum
parallelism (equal to the number of CPU cores). This means that even a
single Jet job uses quite a lot of parallel tasks. Since Jet's
cooperative _tasklets_ are very cheap to switch between, there's almost
no overhead from this. However, every pair of tasklets that communicate
uses a dedicated 1-to-1 concurrent queue so the number of queues scales
with the square of the number of CPU cores. The default queue capacity
is 1024, which translates to 4-8 kilobytes RAM overhead per tasklet pair
and potentially a lot of data items in flight before the queues fill up.

If you experience RAM shortage on the Jet cluster, consider lowering the
queue size. This is how you set the default queue size for the whole Jet
cluster:

[source]
----
include::{javasource}/Considerations.java[tag=s10]
----

You can also set queue sizes individually on each Core API DAG edge.
You must first convert your pipeline to the Core DAG, apply the
configuration, and then submit the DAG for execution:

[source]
----
include::{javasource}/Considerations.java[tag=s10]
----
